{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06bd18b-e761-4061-bcbe-d2e04a11d43a",
   "metadata": {},
   "source": [
    "# Customised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f00408-1d11-4eb4-b6ba-5328c39eeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_chain(model, retriever, rag_prompt = None):\n",
    "    # We will use a prompt template from langchain hub.\n",
    "    if not rag_prompt:\n",
    "        rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # And we will use the LangChain RunnablePassthrough to add some custom processing into our chain.\n",
    "    rag_chain = (\n",
    "            {\n",
    "                \"context\": RunnableLambda(get_question) | retriever | format_docs,\n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | rag_prompt\n",
    "            | model\n",
    "    )\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "def get_question(input):\n",
    "    if not input:\n",
    "        return None\n",
    "    elif isinstance(input,str):\n",
    "        return input\n",
    "    elif isinstance(input,dict) and 'question' in input:\n",
    "        return input['question']\n",
    "    elif isinstance(input,BaseMessage):\n",
    "        return input.content\n",
    "    else:\n",
    "        raise Exception(\"string or dict with 'question' key expected as RAG chain input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684dcdab-1690-41e4-a864-a756df791545",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 635, which is longer than the specified 500\n",
      "Created a chunk of size 868, which is longer than the specified 500\n",
      "Created a chunk of size 606, which is longer than the specified 500\n",
      "Created a chunk of size 1257, which is longer than the specified 500\n",
      "Created a chunk of size 533, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/fish/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fish/anaconda3/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "\n",
    "# Set up the Hugging Face Hub API token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Define the repository ID for the Gemma 2b model\n",
    "repo_id = \"google/gemma-2b-it\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=1024, temperature=1.5\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"bot2/optymize.xlsx\")\n",
    "data_list = df.values.ravel().tolist()\n",
    "document_list = []\n",
    "\n",
    "for content in data_list:\n",
    "    document = Document(content=content, page_content=content)\n",
    "    document_list.append(document)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(document_list)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e962be5-9aa6-4e0e-b926-c9ff3243fc04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_k\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20\u001b[39m})\n\u001b[1;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mpull(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrlm/rag-prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m make_rag_chain(model, retriever, rag_prompt \u001b[38;5;241m=\u001b[39m prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 4, 'fetch_k': 20})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 4, 'fetch_k': 20})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_chain = make_rag_chain(model, retriever, rag_prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bae9bc-6515-46d6-bf1e-222e081039d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "rag_chain = make_rag_chain(llm, retriever) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a4cde1-a7ba-4af0-86fc-33e11264d87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QUESTION:  what is Optymize?\n",
      "\n",
      "--- QUESTION:  how can i deposite coin on Optymize?\n",
      "\n",
      "--- QUESTION:  what is Optymize's twitter?\n",
      "\n",
      "--- QUESTION:  what is gOPZ tokens?\n",
      "\n",
      "--- QUESTION:  what is Optymize tokenomics?\n",
      "\n",
      "--- QUESTION:  what is Optymize details tokenomics?\n",
      "\n",
      "--- QUESTION:  Optymize Vault Model – How does it works?, detail explaination\n",
      "\n",
      "--- QUESTION:  Optymize Vault Model – How does it works?\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "        \"what is Optymize?\",\n",
    "        \"how can i deposite coin on Optymize?\",\n",
    "        \"what is Optymize's twitter?\",\n",
    "        \"what is gOPZ tokens?\",\n",
    "        \"what is Optymize tokenomics?\",\n",
    "        \"what is Optymize details tokenomics?\",\n",
    "        \"Optymize Vault Model – How does it works?, detail explaination\",\n",
    "        \"Optymize Vault Model – How does it works?\"\n",
    "        ]\n",
    "for q in questions:\n",
    "    print(\"\\n--- QUESTION: \", q)\n",
    "    #print(\"* Ans:\\n\", rag_chain.invoke(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c19f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "what is Optymize?\n",
      "<class 'str'>\n",
      "what is Optymize?\n",
      "<class 'str'>\n",
      "what is Optymize?\n",
      "<class 'list'>\n",
      "[Document(page_content='As Optymize would back the creation of Optymize Vault with its stablecoins, this also means the number of Optymize Vaults that can be created would be restrained by the amount of capital Optymize has and the speed users stake to the Optymize Vaults to release Optymize’s stablecoins for further Optymize Vaults creation. In order to speed up the creation of Optymize Vaults to suit the needs of different users, Optymize allows for staking into Liquidity Pools.'), Document(page_content='Essentially users are lending their tokens to Optymize and in return Optymize pays a return to users in the form of OPZ, which users can either sell right away or stake to earn gOPZ and entitle to shar the protocol’s revenue.'), Document(page_content='We encourage our community members to contribute to improve the Optymize protocol. While we will leverage third-party services or protocols to verify (please refer to this link for latest third-party service / protocol we use for determining / confirming a Security Incident) and confirm Security Incident has happened to a token in our Optymize Vault, we would also welcome our community members to report to us (Optymize has a reporting function), which may come in a more timely fashion and help to uncover any missed blindspots .'), Document(page_content='Contact:\\n\\n    X: https://twitter.com/Optymize_xyz \\nTwitter: https://twitter.com/Optymize_xyz \\n    Discord: https://discord.com/invite/NagqntfCnZ \\n    Zealy:https://zealy.io/cw/optymize/questboard')]\n",
      "<class 'dict'>\n",
      "{'context': 'As Optymize would back the creation of Optymize Vault with its stablecoins, this also means the number of Optymize Vaults that can be created would be restrained by the amount of capital Optymize has and the speed users stake to the Optymize Vaults to release Optymize’s stablecoins for further Optymize Vaults creation. In order to speed up the creation of Optymize Vaults to suit the needs of different users, Optymize allows for staking into Liquidity Pools.\\n\\nEssentially users are lending their tokens to Optymize and in return Optymize pays a return to users in the form of OPZ, which users can either sell right away or stake to earn gOPZ and entitle to shar the protocol’s revenue.\\n\\nWe encourage our community members to contribute to improve the Optymize protocol. While we will leverage third-party services or protocols to verify (please refer to this link for latest third-party service / protocol we use for determining / confirming a Security Incident) and confirm Security Incident has happened to a token in our Optymize Vault, we would also welcome our community members to report to us (Optymize has a reporting function), which may come in a more timely fashion and help to uncover any missed blindspots .\\n\\nContact:\\n\\n    X: https://twitter.com/Optymize_xyz \\nTwitter: https://twitter.com/Optymize_xyz \\n    Discord: https://discord.com/invite/NagqntfCnZ \\n    Zealy:https://zealy.io/cw/optymize/questboard', 'question': 'what is Optymize?'}\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is Optymize? \\nContext: As Optymize would back the creation of Optymize Vault with its stablecoins, this also means the number of Optymize Vaults that can be created would be restrained by the amount of capital Optymize has and the speed users stake to the Optymize Vaults to release Optymize’s stablecoins for further Optymize Vaults creation. In order to speed up the creation of Optymize Vaults to suit the needs of different users, Optymize allows for staking into Liquidity Pools.\\n\\nEssentially users are lending their tokens to Optymize and in return Optymize pays a return to users in the form of OPZ, which users can either sell right away or stake to earn gOPZ and entitle to shar the protocol’s revenue.\\n\\nWe encourage our community members to contribute to improve the Optymize protocol. While we will leverage third-party services or protocols to verify (please refer to this link for latest third-party service / protocol we use for determining / confirming a Security Incident) and confirm Security Incident has happened to a token in our Optymize Vault, we would also welcome our community members to report to us (Optymize has a reporting function), which may come in a more timely fashion and help to uncover any missed blindspots .\\n\\nContact:\\n\\n    X: https://twitter.com/Optymize_xyz \\nTwitter: https://twitter.com/Optymize_xyz \\n    Discord: https://discord.com/invite/NagqntfCnZ \\n    Zealy:https://zealy.io/cw/optymize/questboard \\nAnswer:\")]\n",
      "<class 'str'>\n",
      " Optymize allows users to contribute to improving the protocol by staking their tokens in Liquidity Pools. This allows users to earn a return in the form of OPZ tokens, which can be sold, staked, or used to earn gOPZ tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Optymize allows users to contribute to improving the protocol by staking their tokens in Liquidity Pools. This allows users to earn a return in the form of OPZ tokens, which can be sold, staked, or used to earn gOPZ tokens.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1ce4f1-20a0-4318-9534-701042f40627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The Optymize Protocol is a first-of-its-kind multi-blockchain solution that combines both yield enhancement and risk mitigation for crypto assets.\\nExplain more on the keywords here',\n",
       " 'text': '\\n\\n* **Multi-blockchain:** This simply means the protocol operates across multiple blockchain networks. More seamlessly moves money around using a few protocols.\\n\\n\\n* **Yield enhancement:** Imagine increasing rewards earned by holding particular crypto assets in a smart contract. For example, someone could utilize yield farm support in yield-focused DeFi offerings like Defied Protocol or Honeybad to benefit from favorable returns. More rewarding due to increased token supply from other holders participating in the smart contract.\\n\\n\\n* **Risk mitigation:** This ensures stable returns, a layer of resilience to market conditions. What if it ends  to accept token doically (Ifa)? Risk equal zero as assets release( MAT) proxy received two times during banking epoch get their fairchains funciton properly handing to security chart projections. mathematically, approximately everyone on a share gets covered. In less destabilized deposits earned like now liquidity, increased setbacks slam loans refund per-human which typically destroys 99% of deposited tokens. Mixing large numbers that likely construct disapproval gauge enables higer back testing resilience performance needed factor settings.\\n\\n\\n\\n\\nSo overall, the protocol can not only increase earnings via instruments such as Defified Asset, Yield, Bear, VaultSeePro smart contracts but also higher blockchain savings security as investors observe stable safe base as stability fluctuates compared new generation health-focused predictions showcasing new mixed stochastic benchmark so towards bullish terrain pretty much.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\"The Optymize Protocol is a first-of-its-kind multi-blockchain solution that combines both yield enhancement and risk mitigation for crypto assets.\n",
    "Explain more on the keywords here\"\"\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011afd35-5e4a-4b1a-a8a3-8b48e8451f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\n* **Multi-blockchain:** This simply means the protocol operates across multiple blockchain networks. More seamlessly moves money around using a few protocols.\\n\\n\\n* **Yield enhancement:** Imagine increasing rewards earned by holding particular crypto assets in a smart contract. For example, someone could utilize yield farm support in yield-focused DeFi offerings like Defied Protocol or Honeybad to benefit from favorable returns. More rewarding due to increased token supply from other holders participating in the smart contract.\\n\\n\\n* **Risk mitigation:** This ensures stable returns, a layer of resilience to market conditions. What if it ends  to accept token doically (Ifa)? Risk equal zero as assets release( MAT) proxy received two times during banking epoch get their fairchains funciton properly handing to security chart projections. mathematically, approximately everyone on a share gets covered. In less destabilized deposits earned like now liquidity, increased setbacks slam loans refund per-human which typically destroys 99% of deposited tokens. Mixing large numbers that likely construct disapproval gauge enables higer back testing resilience performance needed factor settings.\\n\\n\\n\\n\\nSo overall, the protocol can not only increase earnings via instruments such as Defified Asset, Yield, Bear, VaultSeePro smart contracts but also higher blockchain savings security as investors observe stable safe base as stability fluctuates compared new generation health-focused predictions showcasing new mixed stochastic benchmark so towards bullish terrain pretty much.')]]\n"
     ]
    }
   ],
   "source": [
    "qs = [{'question': question}]\n",
    "res = llm_chain.generate(qs)\n",
    "print(res.generations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
